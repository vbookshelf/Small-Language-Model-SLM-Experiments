{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9462896,"sourceType":"datasetVersion","datasetId":5681136},{"sourceId":197645701,"sourceType":"kernelVersion"}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"- Can handle batch inference\n- Tokenizes the prompts before inference, to speed up inference\n- Use an hf dataset during tokenization because it supports multi-processing\n- Sorts rows by text length so that batches have a similar max length\n- Manually pads the inputs\n","metadata":{}},{"cell_type":"code","source":"!pip install -q bitsandbytes\n!pip install -q accelerate","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:13:33.531504Z","iopub.execute_input":"2024-09-24T11:13:33.532261Z","iopub.status.idle":"2024-09-24T11:14:04.548161Z","shell.execute_reply.started":"2024-09-24T11:13:33.532213Z","shell.execute_reply":"2024-09-24T11:14:04.546980Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport json\nimport time\n\nimport gc\nimport re\nfrom tqdm import tqdm\n\nfrom datasets import Dataset\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom transformers import BatchEncoding\nimport torch\n\n\nimport torch\nfrom transformers import (AutoModelForCausalLM, \n                          AutoTokenizer, \n                          #BitsAndBytesConfig, \n                          AutoConfig)\n\n# Don't Show Warning Messages\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(f\"CUDA Version: {torch.version.cuda}\")\nprint(f\"Pytorch {torch.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:04.550479Z","iopub.execute_input":"2024-09-24T11:14:04.550889Z","iopub.status.idle":"2024-09-24T11:14:09.647048Z","shell.execute_reply.started":"2024-09-24T11:14:04.550844Z","shell.execute_reply":"2024-09-24T11:14:09.645969Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"CUDA Version: 12.3\nPytorch 2.4.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Note:\n# Use cuda:0 for the device because the DriveData\n# environment has only one T4 GPU.\n\nMODEL_PATH = '../input/exp27-youth-download-llama-3-1-8b-8bit/Llama-3.1-8B-Instruct-8bit'\n\n# Use for testing on a small sample of the data\nRUN_TEST = True\nNUM_SAMPLES = 100\n\nBATCH_SIZE = 2\n\nNUM_FOLDS = 5\n\n# Run inference on fold 0\nTEST_FOLD = 0\n\nDEVICE = \"cuda:0\"\n#DEVICE = \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:17.156779Z","iopub.execute_input":"2024-09-24T11:30:17.157194Z","iopub.status.idle":"2024-09-24T11:30:17.162677Z","shell.execute_reply.started":"2024-09-24T11:30:17.157153Z","shell.execute_reply":"2024-09-24T11:30:17.161673Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Set a seed value\n\nimport torch, random\n\n# Ensure that all GPU operations are deterministic \ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nseed_val = 1024\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:09.657467Z","iopub.execute_input":"2024-09-24T11:14:09.658455Z","iopub.status.idle":"2024-09-24T11:14:09.676472Z","shell.execute_reply.started":"2024-09-24T11:14:09.658411Z","shell.execute_reply":"2024-09-24T11:14:09.675608Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"base_path = \"../input/driven-data-youth-mental-health-narratives/youth-mental-health-narratives/automated-abstraction-track/\"","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:09.677677Z","iopub.execute_input":"2024-09-24T11:14:09.678927Z","iopub.status.idle":"2024-09-24T11:14:09.682460Z","shell.execute_reply.started":"2024-09-24T11:14:09.678873Z","shell.execute_reply":"2024-09-24T11:14:09.681662Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\n\nos.listdir('../input/exp27-youth-download-llama-3-1-8b-8bit/Llama-3.1-8B-Instruct-8bit')","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:09.683394Z","iopub.execute_input":"2024-09-24T11:14:09.683728Z","iopub.status.idle":"2024-09-24T11:14:09.699402Z","shell.execute_reply.started":"2024-09-24T11:14:09.683696Z","shell.execute_reply":"2024-09-24T11:14:09.698661Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['model.safetensors.index.json',\n 'config.json',\n 'model-00001-of-00002.safetensors',\n 'model-00002-of-00002.safetensors',\n 'tokenizer.json',\n 'tokenizer_config.json',\n 'special_tokens_map.json',\n 'generation_config.json']"},"metadata":{}}]},{"cell_type":"code","source":"# Check the type and quantity of GPUs\n\nif torch.cuda.is_available():\n    print('Num CPUs:', os.cpu_count())\n    print('Num GPUs:', torch.cuda.device_count())\n    print('GPU Type:', torch.cuda.get_device_name(0))","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:09.700358Z","iopub.execute_input":"2024-09-24T11:14:09.700633Z","iopub.status.idle":"2024-09-24T11:14:09.789506Z","shell.execute_reply.started":"2024-09-24T11:14:09.700603Z","shell.execute_reply":"2024-09-24T11:14:09.788633Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Num CPUs: 4\nNum GPUs: 2\nGPU Type: Tesla T4\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Helper functions","metadata":{}},{"cell_type":"code","source":"def timer(start_time):\n\n    # End timing\n    end_time = time.time()\n    # Calculate the elapsed time\n    elapsed_time = end_time - start_time\n    # round to one decimal place\n    elapsed_time = round(elapsed_time, 1)\n    \n    return elapsed_time\n\n\"\"\"\n# Start timing\nstart_time = time.time()\n\n# Some code\n\n# Get the inference time\nelapsed_time = timer(start_time)\nprint(f\"Time taken: {elapsed_time} seconds\")\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:09.790568Z","iopub.execute_input":"2024-09-24T11:14:09.790867Z","iopub.status.idle":"2024-09-24T11:14:09.797961Z","shell.execute_reply.started":"2024-09-24T11:14:09.790835Z","shell.execute_reply":"2024-09-24T11:14:09.797059Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'\\n# Start timing\\nstart_time = time.time()\\n\\n# Some code\\n\\n# Get the inference time\\nelapsed_time = timer(start_time)\\nprint(f\"Time taken: {elapsed_time} seconds\")\\n'"},"metadata":{}}]},{"cell_type":"code","source":"# Ref: https://github.com/drivendataorg/youth-mental-health-runtime/blob/main/src/scoring.py\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import f1_score\n\n\ndef average_f1(predictions: pd.DataFrame, labels: pd.DataFrame):\n    \"\"\"Score a set of predictions using the competition metric. F1 is averaged\n    across all target variables. For categorical variables, micro-averaged\n    F1 score is used.\n\n    Args:\n        predictions (pd.DataFrame): Dataframe of predictions, with one column\n            for each target variable. The index should be the uid.\n        labels (pd.DataFrame): Dataframe of ground truth values, with one column\n            for each target variable. The index should be the uid.\n    \"\"\"\n    # Check that there are 23 target variables\n    assert predictions.shape[1] == 23\n\n    # Check that column order and row order are the same\n    assert (predictions.columns == labels.columns).all()\n    assert (predictions.index == labels.index).all()\n\n    # All values should be integers\n    assert (predictions.dtypes == int).all()\n\n    CATEGORICAL_VARS = [\"InjuryLocationType\", \"WeaponType1\"]\n    BINARY_VARS = np.setdiff1d(labels.columns, CATEGORICAL_VARS)\n\n    # Calculate F1 score averaged across binary variables\n    binary_f1 = f1_score(\n        labels[BINARY_VARS],\n        predictions[BINARY_VARS],\n        average=\"macro\",\n    )\n    f1s = [binary_f1]\n\n    # Calculate F1 score for each categorical variable\n    for cat_col in CATEGORICAL_VARS:\n        f1s.append(f1_score(labels[cat_col], predictions[cat_col], average=\"micro\"))\n\n    return np.average(f1s, weights=[len(BINARY_VARS), 1, 1])\n\n\ndef calculate_f1(df_predictions, df_labels):\n    \"\"\"\n    Note: \n    1. Set UID as the index\n    2. The dataframes should only contain the binary columns\n    \"\"\"\n    #predictions = pd.read_csv(predictions_path, index_col=\"uid\")\n    #labels = pd.read_csv(labels_path, index_col=\"uid\")\n\n    score = average_f1(df_predictions, df_labels)\n    \n    #print(f\"Variable-averaged F1 score: {score:.4f}\")\n    \n    return score","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:09.799218Z","iopub.execute_input":"2024-09-24T11:14:09.799517Z","iopub.status.idle":"2024-09-24T11:14:10.357556Z","shell.execute_reply.started":"2024-09-24T11:14:09.799487Z","shell.execute_reply":"2024-09-24T11:14:10.356586Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef biased_coin(p_zero=0.5):\n    \"\"\"\n    Returns 0 or 1, with the probability of returning 0 controlled by `p_zero`.\n\n    Args:\n        p_zero (float): Probability of returning 0. Must be between 0 and 1.\n\n    Returns:\n        int: 0 or 1\n    \"\"\"\n    return np.random.choice([0, 1], p=[p_zero, 1 - p_zero])\n\n# Example usage:\nfor _ in range(10):\n    print(biased_coin(p_zero=0.7))  # 70% chance of 0, 30% chance of 1\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:10.361213Z","iopub.execute_input":"2024-09-24T11:14:10.361689Z","iopub.status.idle":"2024-09-24T11:14:10.370948Z","shell.execute_reply.started":"2024-09-24T11:14:10.361655Z","shell.execute_reply":"2024-09-24T11:14:10.369841Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"def assign_batch_numbers(df, batch_size):\n    \"\"\"\n    Assigns a batch number to each row in the DataFrame based on the specified batch size.\n\n    Args:\n    - df (pd.DataFrame): The input dataframe to which batch numbers will be assigned.\n    - batch_size (int): The number of rows in each batch.\n\n    Returns:\n    - pd.DataFrame: A dataframe with an additional 'batch_number' column.\n    \"\"\"\n    # Create a new column 'batch_number' where batch number is assigned to each row\n    df['batch_number'] = (df.index // batch_size) #+ 1\n    return df\n\n# Example Usage\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank', 'Grace'],\n    'Age': [25, 30, 20, 35, 28, 40, 22]\n}\n\ndf = pd.DataFrame(data)\n\n# Assign batch numbers with a batch size of 3\ndf_with_batches = assign_batch_numbers(df, batch_size=3)\n\nnum_batches = df_with_batches['batch_number'].nunique()\n\nprint(num_batches)\n\ndf_with_batches.head(10)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:10.372489Z","iopub.execute_input":"2024-09-24T11:14:10.373357Z","iopub.status.idle":"2024-09-24T11:14:10.400015Z","shell.execute_reply.started":"2024-09-24T11:14:10.373275Z","shell.execute_reply":"2024-09-24T11:14:10.399082Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"3\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"      Name  Age  batch_number\n0    Alice   25             0\n1      Bob   30             0\n2  Charlie   20             0\n3    David   35             1\n4      Eva   28             1\n5    Frank   40             1\n6    Grace   22             2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>batch_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alice</td>\n      <td>25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bob</td>\n      <td>30</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Charlie</td>\n      <td>20</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>David</td>\n      <td>35</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Eva</td>\n      <td>28</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Frank</td>\n      <td>40</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Grace</td>\n      <td>22</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Load the data","metadata":{}},{"cell_type":"code","source":"path = base_path + 'train_features_X4juyT6.csv'\ndf_train_features = pd.read_csv(path)\n\npath = base_path + 'train_labels_JxtENGl.csv'\ndf_train_labels = pd.read_csv(path)\n\n\n# Use merge instead of concat\n# just in case the order of the\n# dataframes is different.\n\ndf_data = pd.merge(df_train_features, df_train_labels, on='uid')\n\nprint(df_data.shape)\n\n#df_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:10.401199Z","iopub.execute_input":"2024-09-24T11:14:10.401593Z","iopub.status.idle":"2024-09-24T11:14:10.599301Z","shell.execute_reply.started":"2024-09-24T11:14:10.401545Z","shell.execute_reply":"2024-09-24T11:14:10.598364Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"(4000, 26)\n","output_type":"stream"}]},{"cell_type":"code","source":"df_data.columns","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:10.600510Z","iopub.execute_input":"2024-09-24T11:14:10.600812Z","iopub.status.idle":"2024-09-24T11:14:10.607340Z","shell.execute_reply.started":"2024-09-24T11:14:10.600780Z","shell.execute_reply":"2024-09-24T11:14:10.606279Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Index(['uid', 'NarrativeLE', 'NarrativeCME', 'DepressedMood',\n       'MentalIllnessTreatmentCurrnt', 'HistoryMentalIllnessTreatmnt',\n       'SuicideAttemptHistory', 'SuicideThoughtHistory',\n       'SubstanceAbuseProblem', 'MentalHealthProblem', 'DiagnosisAnxiety',\n       'DiagnosisDepressionDysthymia', 'DiagnosisBipolar', 'DiagnosisAdhd',\n       'IntimatePartnerProblem', 'FamilyRelationship', 'Argument',\n       'SchoolProblem', 'RecentCriminalLegalProblem', 'SuicideNote',\n       'SuicideIntentDisclosed', 'DisclosedToIntimatePartner',\n       'DisclosedToOtherFamilyMember', 'DisclosedToFriend',\n       'InjuryLocationType', 'WeaponType1'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Pre-process the data","metadata":{}},{"cell_type":"markdown","source":"## Identify rows where the two narrative columns are identical","metadata":{}},{"cell_type":"code","source":"def check_for_duplication(row):\n    \n    NarrativeLE = row['NarrativeLE'].strip()\n    NarrativeCME = row['NarrativeCME'].strip()\n    \n    if NarrativeLE == NarrativeCME:\n        return 'is_duplicated'\n    else:\n        return 'not_duplicated'\n    \ndf_data['dup_narratives'] = df_data.apply(check_for_duplication, axis=1)\n\ndf_data['dup_narratives'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:10.608784Z","iopub.execute_input":"2024-09-24T11:14:10.609207Z","iopub.status.idle":"2024-09-24T11:14:10.684416Z","shell.execute_reply.started":"2024-09-24T11:14:10.609162Z","shell.execute_reply":"2024-09-24T11:14:10.683641Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"dup_narratives\nnot_duplicated    3900\nis_duplicated      100\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df = df_data[df_data['dup_narratives'] == 'is_duplicated']\n\ndf = df.reset_index(drop=True)\n\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:10.685514Z","iopub.execute_input":"2024-09-24T11:14:10.685826Z","iopub.status.idle":"2024-09-24T11:14:10.696665Z","shell.execute_reply.started":"2024-09-24T11:14:10.685792Z","shell.execute_reply":"2024-09-24T11:14:10.694978Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(100, 27)"},"metadata":{}}]},{"cell_type":"code","source":"df.loc[2, 'NarrativeLE']","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:10.697843Z","iopub.execute_input":"2024-09-24T11:14:10.698183Z","iopub.status.idle":"2024-09-24T11:14:10.704674Z","shell.execute_reply.started":"2024-09-24T11:14:10.698148Z","shell.execute_reply":"2024-09-24T11:14:10.703726Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"\"V was a XX XX who hanged himself at his girlfriend's residence. V had been fired the day prior from his job. V left a suicide note with goodbye and love messages for family. V had an unspecified history of suicide attempts. No further circumstances.\""},"metadata":{}}]},{"cell_type":"code","source":"df.loc[2, 'NarrativeCME']","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:10.705973Z","iopub.execute_input":"2024-09-24T11:14:10.706294Z","iopub.status.idle":"2024-09-24T11:14:10.712920Z","shell.execute_reply.started":"2024-09-24T11:14:10.706255Z","shell.execute_reply":"2024-09-24T11:14:10.711961Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"\"V was a XX XX who hanged himself at his girlfriend's residence. V had been fired the day prior from his job. V left a suicide note with goodbye and love messages for family. V had an unspecified history of suicide attempts. No further circumstances.\""},"metadata":{}}]},{"cell_type":"code","source":"# Remove the rows where the narratives are duplicated\ndf_data = df_data[df_data['dup_narratives'] == 'not_duplicated']\n\n# Drop the 'dup_narratives' column\ndf_data = df_data.drop('dup_narratives', axis=1)\n\ndf_data = df_data.reset_index(drop=True)\n\ndf_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:10.714091Z","iopub.execute_input":"2024-09-24T11:14:10.714470Z","iopub.status.idle":"2024-09-24T11:14:10.725729Z","shell.execute_reply.started":"2024-09-24T11:14:10.714421Z","shell.execute_reply":"2024-09-24T11:14:10.724901Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(3900, 26)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Get the string length\nLater we will use this when doing batching.","metadata":{}},{"cell_type":"code","source":"def get_total_text_length(row):\n    \n    text1_len = len(row['NarrativeLE'])\n    text2_len = len(row['NarrativeCME'])\n    \n    total = text1_len + text2_len\n    \n    return total\n\ndf_data['text_length'] = df_data.apply(get_total_text_length, axis=1)\n\nprint(df_data['text_length'].max())\nprint(df_data['text_length'].mean())\nprint(df_data['text_length'].min())","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:10.726847Z","iopub.execute_input":"2024-09-24T11:14:10.727171Z","iopub.status.idle":"2024-09-24T11:14:10.798781Z","shell.execute_reply.started":"2024-09-24T11:14:10.727139Z","shell.execute_reply":"2024-09-24T11:14:10.797953Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"8275\n1770.8687179487179\n386\n","output_type":"stream"}]},{"cell_type":"code","source":"# Example\n\ndf = df_data[df_data['text_length'] <= 386]\n\ndf = df.reset_index(drop=True)\n\n\nprint(df.loc[0, 'NarrativeLE'])\nprint()\nprint(df.loc[0, 'NarrativeCME'])","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:10.799811Z","iopub.execute_input":"2024-09-24T11:14:10.800122Z","iopub.status.idle":"2024-09-24T11:14:10.807831Z","shell.execute_reply.started":"2024-09-24T11:14:10.800089Z","shell.execute_reply":"2024-09-24T11:14:10.806964Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Victim is a XX XX. Victim was diagnosed with bi polar disorder. Victim was homeless. Victim was found hanging by the neck in a loading bay near a grain elevator. Manner of death is suicide.\n\nVictim1, a XX XX XX was found hanging in a loading bay adjacent to a grain elevator.  Toxicology reports positive for Benzoylecgonine, Amphetamines and Methamphetamine.  Manner of death is suicide.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create the 5 folds","metadata":{}},{"cell_type":"code","source":"df_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:10.809007Z","iopub.execute_input":"2024-09-24T11:14:10.809349Z","iopub.status.idle":"2024-09-24T11:14:10.817085Z","shell.execute_reply.started":"2024-09-24T11:14:10.809318Z","shell.execute_reply":"2024-09-24T11:14:10.816114Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(3900, 27)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold, StratifiedGroupKFold\n\nskf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=101)\n\nfor fold, ( _, val_) in enumerate(skf.split(X=df_data, y=df_data.DepressedMood)):\n      df_data.loc[val_ , \"fold\"] = fold\n        \ndf_data['fold'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:10.818391Z","iopub.execute_input":"2024-09-24T11:14:10.819277Z","iopub.status.idle":"2024-09-24T11:14:10.846875Z","shell.execute_reply.started":"2024-09-24T11:14:10.819230Z","shell.execute_reply":"2024-09-24T11:14:10.845978Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"fold\n3.0    780\n0.0    780\n2.0    780\n1.0    780\n4.0    780\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Save the five folds","metadata":{}},{"cell_type":"code","source":"path = 'five_folds.csv'\ndf_data.to_csv(path, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:10.848082Z","iopub.execute_input":"2024-09-24T11:14:10.848717Z","iopub.status.idle":"2024-09-24T11:14:11.187452Z","shell.execute_reply.started":"2024-09-24T11:14:10.848664Z","shell.execute_reply":"2024-09-24T11:14:11.186485Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:11.188520Z","iopub.execute_input":"2024-09-24T11:14:11.189327Z","iopub.status.idle":"2024-09-24T11:14:12.236493Z","shell.execute_reply.started":"2024-09-24T11:14:11.189294Z","shell.execute_reply":"2024-09-24T11:14:12.235402Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"five_folds.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## How to sort and reorder a dataframe","metadata":{}},{"cell_type":"code","source":"# Save the original order\norig_order = list(df_data['uid'])\n\n#orig_order","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:12.238533Z","iopub.execute_input":"2024-09-24T11:14:12.238954Z","iopub.status.idle":"2024-09-24T11:14:12.245286Z","shell.execute_reply.started":"2024-09-24T11:14:12.238898Z","shell.execute_reply":"2024-09-24T11:14:12.244162Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Sort by text_length\n\ndf_sorted = df_data.sort_values(by='text_length', ascending=True)\n\ndf_sorted.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:12.246850Z","iopub.execute_input":"2024-09-24T11:14:12.247221Z","iopub.status.idle":"2024-09-24T11:14:12.275516Z","shell.execute_reply.started":"2024-09-24T11:14:12.247188Z","shell.execute_reply":"2024-09-24T11:14:12.274507Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"       uid                                        NarrativeLE  \\\n1033  bjnj  Victim is a XX XX. Victim was diagnosed with b...   \n1961  cqmf  Officers were dispatched to a residence regard...   \n\n                                           NarrativeCME  DepressedMood  \\\n1033  Victim1, a XX XX XX was found hanging in a loa...              0   \n1961  The victim was a XX XX who died from a self-in...              0   \n\n      MentalIllnessTreatmentCurrnt  HistoryMentalIllnessTreatmnt  \\\n1033                             0                             0   \n1961                             0                             0   \n\n      SuicideAttemptHistory  SuicideThoughtHistory  SubstanceAbuseProblem  \\\n1033                      0                      0                      1   \n1961                      0                      0                      0   \n\n      MentalHealthProblem  ...  RecentCriminalLegalProblem  SuicideNote  \\\n1033                    1  ...                           0            0   \n1961                    0  ...                           0            0   \n\n      SuicideIntentDisclosed  DisclosedToIntimatePartner  \\\n1033                       0                           0   \n1961                       0                           0   \n\n      DisclosedToOtherFamilyMember  DisclosedToFriend  InjuryLocationType  \\\n1033                             0                  0                   6   \n1961                             0                  0                   1   \n\n      WeaponType1  text_length  fold  \n1033            6          386   1.0  \n1961            5          388   1.0  \n\n[2 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>NarrativeLE</th>\n      <th>NarrativeCME</th>\n      <th>DepressedMood</th>\n      <th>MentalIllnessTreatmentCurrnt</th>\n      <th>HistoryMentalIllnessTreatmnt</th>\n      <th>SuicideAttemptHistory</th>\n      <th>SuicideThoughtHistory</th>\n      <th>SubstanceAbuseProblem</th>\n      <th>MentalHealthProblem</th>\n      <th>...</th>\n      <th>RecentCriminalLegalProblem</th>\n      <th>SuicideNote</th>\n      <th>SuicideIntentDisclosed</th>\n      <th>DisclosedToIntimatePartner</th>\n      <th>DisclosedToOtherFamilyMember</th>\n      <th>DisclosedToFriend</th>\n      <th>InjuryLocationType</th>\n      <th>WeaponType1</th>\n      <th>text_length</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1033</th>\n      <td>bjnj</td>\n      <td>Victim is a XX XX. Victim was diagnosed with b...</td>\n      <td>Victim1, a XX XX XX was found hanging in a loa...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>6</td>\n      <td>386</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1961</th>\n      <td>cqmf</td>\n      <td>Officers were dispatched to a residence regard...</td>\n      <td>The victim was a XX XX who died from a self-in...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>388</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 28 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Go back to the original order\n\n# Set the \"uid\" column as the index\ndf_data = df_data.set_index('uid')\n\n# Go back to the orginal row order\ndf_data = df_data.reindex(orig_order)\n\n# Reset the index while keeping the \"uid\" column\ndf_data = df_data.reset_index(drop=False)\n\n#df_data.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:12.276819Z","iopub.execute_input":"2024-09-24T11:14:12.277161Z","iopub.status.idle":"2024-09-24T11:14:12.287288Z","shell.execute_reply.started":"2024-09-24T11:14:12.277127Z","shell.execute_reply":"2024-09-24T11:14:12.286373Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#orig_order","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:12.294263Z","iopub.execute_input":"2024-09-24T11:14:12.294549Z","iopub.status.idle":"2024-09-24T11:14:12.298743Z","shell.execute_reply.started":"2024-09-24T11:14:12.294518Z","shell.execute_reply":"2024-09-24T11:14:12.297671Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Inference helper functions","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:12.300094Z","iopub.execute_input":"2024-09-24T11:14:12.300437Z","iopub.status.idle":"2024-09-24T11:14:12.320336Z","shell.execute_reply.started":"2024-09-24T11:14:12.300389Z","shell.execute_reply":"2024-09-24T11:14:12.319093Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"    uid                                        NarrativeLE  \\\n0  bjnj  Victim is a XX XX. Victim was diagnosed with b...   \n\n                                        NarrativeCME  DepressedMood  \\\n0  Victim1, a XX XX XX was found hanging in a loa...              0   \n\n   MentalIllnessTreatmentCurrnt  HistoryMentalIllnessTreatmnt  \\\n0                             0                             0   \n\n   SuicideAttemptHistory  SuicideThoughtHistory  SubstanceAbuseProblem  \\\n0                      0                      0                      1   \n\n   MentalHealthProblem  ...  SchoolProblem  RecentCriminalLegalProblem  \\\n0                    1  ...              0                           0   \n\n   SuicideNote  SuicideIntentDisclosed  DisclosedToIntimatePartner  \\\n0            0                       0                           0   \n\n   DisclosedToOtherFamilyMember  DisclosedToFriend  InjuryLocationType  \\\n0                             0                  0                   6   \n\n   WeaponType1  text_length  \n0            6          386  \n\n[1 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>NarrativeLE</th>\n      <th>NarrativeCME</th>\n      <th>DepressedMood</th>\n      <th>MentalIllnessTreatmentCurrnt</th>\n      <th>HistoryMentalIllnessTreatmnt</th>\n      <th>SuicideAttemptHistory</th>\n      <th>SuicideThoughtHistory</th>\n      <th>SubstanceAbuseProblem</th>\n      <th>MentalHealthProblem</th>\n      <th>...</th>\n      <th>SchoolProblem</th>\n      <th>RecentCriminalLegalProblem</th>\n      <th>SuicideNote</th>\n      <th>SuicideIntentDisclosed</th>\n      <th>DisclosedToIntimatePartner</th>\n      <th>DisclosedToOtherFamilyMember</th>\n      <th>DisclosedToFriend</th>\n      <th>InjuryLocationType</th>\n      <th>WeaponType1</th>\n      <th>text_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bjnj</td>\n      <td>Victim is a XX XX. Victim was diagnosed with b...</td>\n      <td>Victim1, a XX XX XX was found hanging in a loa...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>6</td>\n      <td>386</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 27 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_batch(df):\n    \"\"\"\n    Inputs:\n    df - A batch of prompts in a pandas dataframe\n    \n    Outputs:\n    inputs - a a dict containing the tokenized batch\n    \"\"\"\n    \n    prompt_list = list(df['prompts'])\n    \n    # Get the num CPU cores available\n    num_workers = os.cpu_count()\n    \n    # Tokenize the prompts\n    inputs = tokenizer(prompt_list, \n                       return_tensors=\"pt\",\n                        #padding=True, \n                       #num_workers=num_workers\n                      )\n    \n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:12.321786Z","iopub.execute_input":"2024-09-24T11:14:12.322167Z","iopub.status.idle":"2024-09-24T11:14:12.330072Z","shell.execute_reply.started":"2024-09-24T11:14:12.322128Z","shell.execute_reply":"2024-09-24T11:14:12.329045Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def run_slm_with_batches(inputs):\n\n    # Send the inputs to the device\n    inputs = inputs.to(DEVICE)\n\n    # Generate the outputs from prompt\n    generate_ids = model.generate(**inputs, \n                                  max_new_tokens=512,\n                                  do_sample=False,\n                                  temperature=0.1\n                                 )\n    \n    # Decode the generated output\n    generated_text_list = tokenizer.batch_decode(generate_ids, \n                                        skip_special_tokens=False,\n                                        clean_up_tokenization_spaces=False)\n    \n    \n    # Extract the answer\n    # -------------------\n    \n    response_list = []\n    \n    for i in range(0, len(generated_text_list)):\n        \n        response = generated_text_list[i]\n        \n        # Extract the answer\n        # Split\n        response = response.split('<|assistant|>')[1]\n\n        # Remove leading and trailing spaces\n        response = response.strip()\n        \n        response_list.append(response)\n        \n    # Create a new column containing the raw responses   \n    df['raw_responses'] = response_list\n        \n    return df\n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:12.331749Z","iopub.execute_input":"2024-09-24T11:14:12.332409Z","iopub.status.idle":"2024-09-24T11:14:12.341576Z","shell.execute_reply.started":"2024-09-24T11:14:12.332364Z","shell.execute_reply":"2024-09-24T11:14:12.340640Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Post process the responses\n\ndef post_process_responses(df):\n    \n    master_key_list = [\n    \"DepressedMood\",\n    \"MentalIllnessTreatmentCurrnt\", \n    \"HistoryMentalIllnessTreatmnt\",\n    \"SuicideAttemptHistory\", \n    \"SuicideThoughtHistory\",\n    \"SubstanceAbuseProblem\", \n    \"MentalHealthProblem\", \n    \"DiagnosisAnxiety\",\n    \"DiagnosisDepressionDysthymia\", \n    \"DiagnosisBipolar\", \n    \"DiagnosisAdhd\",\n    \"IntimatePartnerProblem\", \n    \"FamilyRelationship\", \n    \"Argument\",\n    \"SchoolProblem\", \n    \"RecentCriminalLegalProblem\", \n    \"SuicideNote\",\n    \"SuicideIntentDisclosed\", \n    \"DisclosedToIntimatePartner\",\n    \"DisclosedToOtherFamilyMember\", \n    \"DisclosedToFriend\",\n    \"InjuryLocationType\",\n    \"WeaponType1\"\n    ]\n\n    \n    uid_list = []\n\n    DepressedMood_list = []\n    MentalIllnessTreatmentCurrnt_list = []\n    HistoryMentalIllnessTreatmnt_list = []\n    SuicideAttemptHistory_list = []\n    SuicideThoughtHistory_list = []\n    SubstanceAbuseProblem_list = []\n    MentalHealthProblem_list = []\n\n    DiagnosisAnxiety_list = []\n    DiagnosisDepressionDysthymia_list = []\n    DiagnosisBipolar_list = []\n    DiagnosisAdhd_list = []\n\n    IntimatePartnerProblem_list = []\n    FamilyRelationship_list = []\n    Argument_list = []\n    SchoolProblem_list = []\n    RecentCriminalLegalProblem_list = []\n\n    SuicideNote_list = []\n    SuicideIntentDisclosed_list = []\n    DisclosedToIntimatePartner_list = []\n    DisclosedToOtherFamilyMember_list = []\n    DisclosedToFriend_list = []\n\n    InjuryLocationType_list = []\n    WeaponType1_list = []\n\n    \n    for i in range(0, len(df)):\n        \n        try:\n            uid = df.loc[i,'uid']\n\n            response = df.loc[i, 'raw_responses']\n            #response = data_dict['response']\n            \n            \n\n            # Remove the end token\n            response = response.replace('<|end|><|endoftext|>', \"\")\n            response = response.replace('<|end|>', \"\")\n            response = response.replace('```json', \"\")\n            response = response.replace('```', \"\")\n\n\n            # The model can output text in addition to JSON.\n            # Use regular expression to extract JSON part from the response.\n            # Regular expression to match one set of curly braces and everything inside\n            pattern = r'\\{[^}]*\\}'\n\n            # Find and extract the first match\n            match = re.search(pattern, response)\n\n            if match:\n                response = match.group()  # Output: {extract this}\n\n            response_json = json.loads(response)\n\n            # Check if all keys are in the response an\n            # that they can be accessed with an error.\n            # This steps ensures that all arrays have\n            # the same length\n            check_list = []\n            pred_json_key_list = response_json.keys()\n            for item in master_key_list:\n                if item not in pred_json_key_list:\n                    check_list.append(0)\n\n\n            if len(check_list) == 0:\n\n                uid_list.append(uid)\n\n                DepressedMood_list.append(response_json['DepressedMood'])\n                MentalIllnessTreatmentCurrnt_list.append(response_json['MentalIllnessTreatmentCurrnt'])\n                HistoryMentalIllnessTreatmnt_list.append(response_json['HistoryMentalIllnessTreatmnt'])\n                SuicideAttemptHistory_list.append(response_json['SuicideAttemptHistory'])\n                SuicideThoughtHistory_list.append(response_json['SuicideThoughtHistory'])\n                SubstanceAbuseProblem_list.append(response_json['SubstanceAbuseProblem'])\n                MentalHealthProblem_list.append(response_json['MentalHealthProblem'])\n\n                DiagnosisAnxiety_list.append(response_json['DiagnosisAnxiety'])\n                DiagnosisDepressionDysthymia_list.append(response_json['DiagnosisDepressionDysthymia'])\n                DiagnosisBipolar_list.append(response_json['DiagnosisBipolar'])\n                DiagnosisAdhd_list.append(response_json['DiagnosisAdhd'])\n\n                IntimatePartnerProblem_list.append(response_json['IntimatePartnerProblem'])\n                FamilyRelationship_list.append(response_json['FamilyRelationship'])\n                Argument_list.append(response_json['Argument'])\n                SchoolProblem_list.append(response_json['SchoolProblem'])\n                RecentCriminalLegalProblem_list.append(response_json['RecentCriminalLegalProblem'])\n\n                SuicideNote_list.append(response_json['SuicideNote'])\n                SuicideIntentDisclosed_list.append(response_json['SuicideIntentDisclosed'])\n                DisclosedToIntimatePartner_list.append(response_json['DisclosedToIntimatePartner'])\n                DisclosedToOtherFamilyMember_list.append(response_json['DisclosedToOtherFamilyMember'])\n                DisclosedToFriend_list.append(response_json['DisclosedToFriend'])\n\n                InjuryLocationType_list.append(response_json['InjuryLocationType'])\n                WeaponType1_list.append(response_json['WeaponType1'])\n\n\n            else:\n                print(\"There as an issue with JSON keys.\")\n                print(\"Predicting all ones...\")\n                print(response)\n                \n                uid_list.append(uid)\n\n                DepressedMood_list.append('yes')\n                MentalIllnessTreatmentCurrnt_list.append('yes')\n                HistoryMentalIllnessTreatmnt_list.append('yes')\n                SuicideAttemptHistory_list.append('yes')\n                SuicideThoughtHistory_list.append('yes')\n                SubstanceAbuseProblem_list.append('yes')\n                MentalHealthProblem_list.append('yes')\n\n                DiagnosisAnxiety_list.append('yes')\n                DiagnosisDepressionDysthymia_list.append('yes')\n                DiagnosisBipolar_list.append('yes')\n                DiagnosisAdhd_list.append('yes')\n\n                IntimatePartnerProblem_list.append('yes')\n                FamilyRelationship_list.append('yes')\n                Argument_list.append('yes')\n                SchoolProblem_list.append('yes')\n                RecentCriminalLegalProblem_list.append('yes')\n\n                SuicideNote_list.append('yes')\n                SuicideIntentDisclosed_list.append('yes')\n                DisclosedToIntimatePartner_list.append('yes')\n                DisclosedToOtherFamilyMember_list.append('yes')\n                DisclosedToFriend_list.append('yes')\n\n                InjuryLocationType_list.append(1)\n                WeaponType1_list.append(5)\n\n        \n        except Exception as e:\n            \n            print('--Exception error--')\n            print(e)\n\n            print(f\"uid: {uid}\")\n            print('Possible json error...')\n            print('Predicting all ones')\n\n            print(response)\n\n            uid_list.append(uid)\n\n            DepressedMood_list.append('yes')\n            MentalIllnessTreatmentCurrnt_list.append('yes')\n            HistoryMentalIllnessTreatmnt_list.append('yes')\n            SuicideAttemptHistory_list.append('yes')\n            SuicideThoughtHistory_list.append('yes')\n            SubstanceAbuseProblem_list.append('yes')\n            MentalHealthProblem_list.append('yes')\n\n            DiagnosisAnxiety_list.append('yes')\n            DiagnosisDepressionDysthymia_list.append('yes')\n            DiagnosisBipolar_list.append('yes')\n            DiagnosisAdhd_list.append('yes')\n\n            IntimatePartnerProblem_list.append('yes')\n            FamilyRelationship_list.append('yes')\n            Argument_list.append('yes')\n            SchoolProblem_list.append('yes')\n            RecentCriminalLegalProblem_list.append('yes')\n\n            SuicideNote_list.append('yes')\n            SuicideIntentDisclosed_list.append('yes')\n            DisclosedToIntimatePartner_list.append('yes')\n            DisclosedToOtherFamilyMember_list.append('yes')\n            DisclosedToFriend_list.append('yes')\n\n            InjuryLocationType_list.append(1)\n            WeaponType1_list.append(5)\n\n\n    data = {\n            \"uid\": uid_list,\n\n            \"DepressedMood\": DepressedMood_list,\n            \"MentalIllnessTreatmentCurrnt\": MentalIllnessTreatmentCurrnt_list,\n            \"HistoryMentalIllnessTreatmnt\": HistoryMentalIllnessTreatmnt_list,\n            \"SuicideAttemptHistory\": SuicideAttemptHistory_list,\n            \"SuicideThoughtHistory\": SuicideThoughtHistory_list,\n            \"SubstanceAbuseProblem\": SubstanceAbuseProblem_list,\n            \"MentalHealthProblem\": MentalHealthProblem_list,\n\n            \"DiagnosisAnxiety\": DiagnosisAnxiety_list,\n            \"DiagnosisDepressionDysthymia\": DiagnosisDepressionDysthymia_list,\n            \"DiagnosisBipolar\": DiagnosisBipolar_list,\n            \"DiagnosisAdhd\": DiagnosisAdhd_list,\n\n            \"IntimatePartnerProblem\": IntimatePartnerProblem_list,\n            \"FamilyRelationship\": FamilyRelationship_list,\n            \"Argument\": Argument_list,\n            \"SchoolProblem\": SchoolProblem_list,\n            \"RecentCriminalLegalProblem\": RecentCriminalLegalProblem_list,\n\n            \"SuicideNote\": SuicideNote_list,\n            \"SuicideIntentDisclosed\": SuicideIntentDisclosed_list,\n            \"DisclosedToIntimatePartner\": DisclosedToIntimatePartner_list,\n            \"DisclosedToOtherFamilyMember\": DisclosedToOtherFamilyMember_list,\n            \"DisclosedToFriend\": DisclosedToFriend_list,\n\n            \"InjuryLocationType\": InjuryLocationType_list,\n            \"WeaponType1\": WeaponType1_list \n            }\n\n    df_preds = pd.DataFrame(data)\n    \n    return df_preds\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:12.343102Z","iopub.execute_input":"2024-09-24T11:14:12.343561Z","iopub.status.idle":"2024-09-24T11:14:12.387889Z","shell.execute_reply.started":"2024-09-24T11:14:12.343516Z","shell.execute_reply":"2024-09-24T11:14:12.386991Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def tokenize_prompts(df):\n    \n    \"\"\"\n    Input: Pandas dataframe with a column named prompts.\n    Output: Pandas dataframe with the input_ids and att_mask\n    for each prompt.\n    \n    \"\"\"\n    \n    # Convert pandas DataFrame to Huggingface Dataset\n    dataset = Dataset.from_pandas(df)\n    \n    # Get the num CPU cores available\n    num_workers = os.cpu_count()\n\n    # Tokenize using the Huggingface dataset `map` function, without truncation\n    def tokenize_function(examples):\n        \n        return tokenizer(examples['prompts'], \n                         padding=False,  # Add padding\n                         truncation=False)  # Disable truncation\n    \n    # Apply tokenization across the dataset in parallel\n    tokenized_dataset = dataset.map(tokenize_function, \n                                    batched=True, \n                                    num_proc=num_workers)\n    \n    # Convert Hugging Face Dataset to pandas DataFrame\n    df = tokenized_dataset.to_pandas()\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:12.389661Z","iopub.execute_input":"2024-09-24T11:14:12.390049Z","iopub.status.idle":"2024-09-24T11:14:12.401065Z","shell.execute_reply.started":"2024-09-24T11:14:12.390006Z","shell.execute_reply":"2024-09-24T11:14:12.400161Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Create the system message","metadata":{}},{"cell_type":"code","source":"system_message = f\"\"\"\nYou are an expert legal assistant.\n\nYou will be provided with a narrative about a person who has committed suicide. \nYour task is to answer questions about the content of the narrative. You must be able to support your\nanswers with facts from the narrative.\n\n<categories>\n\n### Answer only \"yes\" or \"no\":\n\n1. DepressedMood: Was the victim was perceived to be depressed at the time?\n2. MentalIllnessTreatmentCurrnt: Was the victim currently undergoing medical treatment for a mental health or substance abuse problem?\n3. HistoryMentalIllnessTreatmnt: Did the victim have a history of ever being treated for a mental health or substance abuse problem?\n4. SuicideAttemptHistory: Did the victim have a history of attempting suicide?\n5. SuicideThoughtHistory: Did the victim have a history of suicidal thoughts or plans?\n6. SubstanceAbuseProblem: Did the victim struggle with a substance abuse problem?\n7. MentalHealthProblem: Did the victim have a mental health condition at the time?\n\n8. DiagnosisAnxiety: Was the victim ever diagnosed with Anxiety?\n9. DiagnosisDepressionDysthymia: Was the victim ever diagnosed with Dysthymia?\n10. DiagnosisBipolar: Was the victim ever diagnosed as being Bipolar?\n11. DiagnosisAdhd: Was the victim ever diagnosed with Adhd?\n\n12. IntimatePartnerProblem: Did problems with a current or former intimate partner appear to have contributed to the victim's suicide?\n13. FamilyRelationship: Did relationship problems with a family member (other than an intimate partner) appear to have contributed to the victim's suicide? \n14. Argument: Did an argument or conflict appear to have contributed to the victim's suicide?\n15. SchoolProblem: Did problems at or related to school appear to have contributed to the victim's suicide? \n16. RecentCriminalLegalProblem: Did criminal legal problem(s) appear to have contributed to the victim's suicide?\n\n17. SuicideNote: Did the victim leave a suicide note?\n18. SuicideIntentDisclosed: Did the victim disclose their thoughts and/or plans to die by suicide to someone else within the last month? \n19. DisclosedToIntimatePartner: Did the victim disclose their intent to commit suicide to a previous or current intimate partner?\n20. DisclosedToOtherFamilyMember: Did the victim disclose their intent to commit suicide to another family member?\n21. DisclosedToFriend:  Did the victim disclose their intent to commit suicide to a friend?\n\n### Answer by returning an integer:\n\n22. InjuryLocationType: Where did the suicide take place?\n    (Choose only one option and return only the number e.g. 1)\n    1. House/apartment,\n    2. Motor vehicle (excluding school bus and public transportation)\n    3. Natural area (e.g., field, river, beaches, woods)\n    4. Park, playground, public use area\n    5. Street/road, sidewalk, alley\n    6. Other\n23. WeaponType1: What type of weapon/means did the victim use to commit suicide?\n    (Choose only one option and return only the number e.g. 1)\n    1. Blunt instrument\n    2. Drowning\n    3. Fall\n    4. Fire or burns\n    5. Firearm\n    6. Hanging, strangulation, suffocation\n    7. Motor vehicle including buses, motorcycles\n    8. Other transport vehicle, eg, trains, planes, boats\n    9. Poisoning\n    10. Sharp instrument\n    11. Other (e.g. taser, electrocution, nail gun)\n    12. Unknown\n</categories>\n \nFormat your response as JSON, without any prefixes, with the following 23 keys:\n'DepressedMood','MentalIllnessTreatmentCurrnt', 'HistoryMentalIllnessTreatmnt',\n'SuicideAttemptHistory', 'SuicideThoughtHistory',\n'SubstanceAbuseProblem', 'MentalHealthProblem', 'DiagnosisAnxiety',\n'DiagnosisDepressionDysthymia', 'DiagnosisBipolar', 'DiagnosisAdhd',\n'IntimatePartnerProblem', 'FamilyRelationship', 'Argument',\n'SchoolProblem', 'RecentCriminalLegalProblem', 'SuicideNote',\n'SuicideIntentDisclosed', 'DisclosedToIntimatePartner',\n'DisclosedToOtherFamilyMember', 'DisclosedToFriend',\n'InjuryLocationType', 'WeaponType1'\n\n### Example output:\n{{\n\"DepressedMood\": \"<your-answer>\",\n\"MentalIllnessTreatmentCurrnt\": \"<your-answer>\", \n\"HistoryMentalIllnessTreatmnt\": \"<your-answer>\",\n\"SuicideAttemptHistory\": \"<your-answer>\", \n\"SuicideThoughtHistory\": \"<your-answer>\",\n\"SubstanceAbuseProblem\": \"<your-answer>\", \n\"MentalHealthProblem\": \"<your-answer>\", \n\"DiagnosisAnxiety\": \"<your-answer>\",\n\"DiagnosisDepressionDysthymia\": \"<your-answer>\", \n\"DiagnosisBipolar\": \"<your-answer>\", \n\"DiagnosisAdhd\": \"<your-answer>\",\n\"IntimatePartnerProblem\": \"<your-answer>\", \n\"FamilyRelationship\": \"<your-answer>\", \n\"Argument\": \"<your-answer>\",\n\"SchoolProblem\": \"<your-answer>\", \n\"RecentCriminalLegalProblem\": \"<your-answer>\", \n\"SuicideNote\": \"<your-answer>\",\n\"SuicideIntentDisclosed\": \"<your-answer>\", \n\"DisclosedToIntimatePartner\": \"<your-answer>\",\n\"DisclosedToOtherFamilyMember\": \"<your-answer>\", \n\"DisclosedToFriend\": \"<your-answer>\",\n\"InjuryLocationType\": \"<integer>\",\n\"WeaponType1\": \"<integer>\"\n}}\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:12.402618Z","iopub.execute_input":"2024-09-24T11:14:12.403030Z","iopub.status.idle":"2024-09-24T11:14:12.414536Z","shell.execute_reply.started":"2024-09-24T11:14:12.402961Z","shell.execute_reply":"2024-09-24T11:14:12.413429Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"## Create the prompts","metadata":{}},{"cell_type":"code","source":"def create_prompts(row):\n    \n    NarrativeLE = row['NarrativeLE']\n    NarrativeCME = row['NarrativeCME']\n\n    user_query = f\"Law enforcement report: {NarrativeLE}\\nMedical examiner report: {NarrativeCME}\\nFormat your response as JSON, without any prefixes.\"\n\n    # Create the prompt template\n    prompt = f\"<|system|>{system_message}<|end|><|user|>{user_query}<|end|><|assistant|>\"\n    \n    return prompt\n\ndf_data['prompts'] = df_data.apply(create_prompts, axis=1)\n\n#df_data.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:12.416055Z","iopub.execute_input":"2024-09-24T11:14:12.416455Z","iopub.status.idle":"2024-09-24T11:14:12.517362Z","shell.execute_reply.started":"2024-09-24T11:14:12.416411Z","shell.execute_reply":"2024-09-24T11:14:12.516615Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"#df_data.loc[0, 'prompts']","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:12.518572Z","iopub.execute_input":"2024-09-24T11:14:12.519313Z","iopub.status.idle":"2024-09-24T11:14:12.523250Z","shell.execute_reply.started":"2024-09-24T11:14:12.519269Z","shell.execute_reply":"2024-09-24T11:14:12.522358Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"## Tokenize all the prompts\n\nWe will use a hf dataset instead of pandas to take advantage of multi-processing.","metadata":{}},{"cell_type":"code","source":"# Start timing\nstart_time = time.time()\n\n\n# Initialize the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n\n# Tokenize all the prompts, without adding padding.\ndf_data = tokenize_prompts(df_data)\n\nprint(df_data.shape)\n\n# Get the inference time\nelapsed_time = timer(start_time)\nelapsed_time = elapsed_time/60\nprint(f\"Time taken: {elapsed_time} minutes\")\n\ndf_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:12.524407Z","iopub.execute_input":"2024-09-24T11:14:12.524718Z","iopub.status.idle":"2024-09-24T11:14:22.616661Z","shell.execute_reply.started":"2024-09-24T11:14:12.524686Z","shell.execute_reply":"2024-09-24T11:14:22.615595Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/3900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"303bc42033234a60801294994bcf1566"}},"metadata":{}},{"name":"stdout","text":"(3900, 31)\nTime taken: 0.16833333333333333 minutes\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"    uid                                        NarrativeLE  \\\n0  aaaf  V (XX XX) shot himself in a motor vehicle.The ...   \n1  aaby  V was XXXX. V was found in the basement of his...   \n\n                                        NarrativeCME  DepressedMood  \\\n0  V (XX XX) shot himself in a motor vehicle.The ...              0   \n1  V was XXXX.  V was found in the basement of hi...              0   \n\n   MentalIllnessTreatmentCurrnt  HistoryMentalIllnessTreatmnt  \\\n0                             0                             0   \n1                             0                             0   \n\n   SuicideAttemptHistory  SuicideThoughtHistory  SubstanceAbuseProblem  \\\n0                      0                      1                      0   \n1                      0                      0                      0   \n\n   MentalHealthProblem  ...  DisclosedToIntimatePartner  \\\n0                    0  ...                           0   \n1                    0  ...                           0   \n\n   DisclosedToOtherFamilyMember  DisclosedToFriend  InjuryLocationType  \\\n0                             1                  0                   2   \n1                             0                  0                   1   \n\n   WeaponType1  text_length  fold  \\\n0            5          628   3.0   \n1            6          778   0.0   \n\n                                             prompts  \\\n0  <|system|>\\nYou are an expert legal assistant....   \n1  <|system|>\\nYou are an expert legal assistant....   \n\n                                           input_ids  \\\n0  [128000, 27, 91, 9125, 91, 397, 2675, 527, 459...   \n1  [128000, 27, 91, 9125, 91, 397, 2675, 527, 459...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n\n[2 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>NarrativeLE</th>\n      <th>NarrativeCME</th>\n      <th>DepressedMood</th>\n      <th>MentalIllnessTreatmentCurrnt</th>\n      <th>HistoryMentalIllnessTreatmnt</th>\n      <th>SuicideAttemptHistory</th>\n      <th>SuicideThoughtHistory</th>\n      <th>SubstanceAbuseProblem</th>\n      <th>MentalHealthProblem</th>\n      <th>...</th>\n      <th>DisclosedToIntimatePartner</th>\n      <th>DisclosedToOtherFamilyMember</th>\n      <th>DisclosedToFriend</th>\n      <th>InjuryLocationType</th>\n      <th>WeaponType1</th>\n      <th>text_length</th>\n      <th>fold</th>\n      <th>prompts</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aaaf</td>\n      <td>V (XX XX) shot himself in a motor vehicle.The ...</td>\n      <td>V (XX XX) shot himself in a motor vehicle.The ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>5</td>\n      <td>628</td>\n      <td>3.0</td>\n      <td>&lt;|system|&gt;\\nYou are an expert legal assistant....</td>\n      <td>[128000, 27, 91, 9125, 91, 397, 2675, 527, 459...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aaby</td>\n      <td>V was XXXX. V was found in the basement of his...</td>\n      <td>V was XXXX.  V was found in the basement of hi...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>778</td>\n      <td>0.0</td>\n      <td>&lt;|system|&gt;\\nYou are an expert legal assistant....</td>\n      <td>[128000, 27, 91, 9125, 91, 397, 2675, 527, 459...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def create_tokenized_batch_fast(df_tok):\n    \n    \"\"\"\n    Input:\n    A batch as a pandas dataframe containing input_ids \n    and attention_mask for each prompt. \n    These are lists and they are not padded.\n    \n    Output:\n    A tokenized batch that's ready for batch inference.\n    \"\"\"\n\n    # 32000\n    pad_token = tokenizer.convert_tokens_to_ids(tokenizer.eos_token)\n\n    # Create a column with the length of each list\n    def get_lengths(x):\n        length = len(x)\n        return length\n\n    df_tok['length'] = df_tok['input_ids'].apply(get_lengths)\n\n    # Get the length of the longest prompt in the batch\n    max_len = df_tok['length'].max()\n    \n\n    # Pad the input_ids with the pad token\n    def pad_input_ids(x):\n\n        pad_token = tokenizer.convert_tokens_to_ids(tokenizer.eos_token)\n        padded_list = np.pad(x, (0, max_len - len(x)), \n                              mode='constant', constant_values=pad_token)\n\n        return padded_list\n\n    df_tok['padded_input_ids'] = df_tok['input_ids'].apply(pad_input_ids)\n\n\n    # Pad the attention_masks with 0\n    def pad_attention_mask(x):\n\n        padded_list = np.pad(x, (0, max_len - len(x)), \n                              mode='constant', constant_values=0)\n\n        return padded_list\n\n    df_tok['padded_attention_mask'] = df_tok['attention_mask'].apply(pad_input_ids)\n\n\n    tokenized_batch = {\n        \"input_ids\": torch.tensor(list(df_tok['padded_input_ids'])),\n        \"attention_mask\": torch.tensor(list(df_tok['padded_attention_mask']))\n    }\n\n    return tokenized_batch","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:22.618278Z","iopub.execute_input":"2024-09-24T11:14:22.618591Z","iopub.status.idle":"2024-09-24T11:14:22.628711Z","shell.execute_reply.started":"2024-09-24T11:14:22.618556Z","shell.execute_reply":"2024-09-24T11:14:22.627726Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Example of tokeninizing one batch\n\ni = 0\n\n# Reorder by text length\ndf_sorted = df_data.sort_values(by='text_length', ascending=True)\ndf_sorted = df_sorted.reset_index(drop=True)\n\n# Assign a batch number to every row\nbatch_size = 5\ndf_sorted = assign_batch_numbers(df_sorted, batch_size)\n\n# Get the batch\ndf = df_sorted[df_sorted['batch_number'] == i]\ndf = df.reset_index(drop=True)\n\nprint(df.shape)\n\ndf.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:22.630067Z","iopub.execute_input":"2024-09-24T11:14:22.630445Z","iopub.status.idle":"2024-09-24T11:14:23.389126Z","shell.execute_reply.started":"2024-09-24T11:14:22.630400Z","shell.execute_reply":"2024-09-24T11:14:23.388171Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"(5, 32)\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"    uid                                        NarrativeLE  \\\n0  bjnj  Victim is a XX XX. Victim was diagnosed with b...   \n\n                                        NarrativeCME  DepressedMood  \\\n0  Victim1, a XX XX XX was found hanging in a loa...              0   \n\n   MentalIllnessTreatmentCurrnt  HistoryMentalIllnessTreatmnt  \\\n0                             0                             0   \n\n   SuicideAttemptHistory  SuicideThoughtHistory  SubstanceAbuseProblem  \\\n0                      0                      0                      1   \n\n   MentalHealthProblem  ...  DisclosedToOtherFamilyMember  DisclosedToFriend  \\\n0                    1  ...                             0                  0   \n\n   InjuryLocationType  WeaponType1  text_length  fold  \\\n0                   6            6          386   1.0   \n\n                                             prompts  \\\n0  <|system|>\\nYou are an expert legal assistant....   \n\n                                           input_ids  \\\n0  [128000, 27, 91, 9125, 91, 397, 2675, 527, 459...   \n\n                                      attention_mask  batch_number  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...             0  \n\n[1 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>NarrativeLE</th>\n      <th>NarrativeCME</th>\n      <th>DepressedMood</th>\n      <th>MentalIllnessTreatmentCurrnt</th>\n      <th>HistoryMentalIllnessTreatmnt</th>\n      <th>SuicideAttemptHistory</th>\n      <th>SuicideThoughtHistory</th>\n      <th>SubstanceAbuseProblem</th>\n      <th>MentalHealthProblem</th>\n      <th>...</th>\n      <th>DisclosedToOtherFamilyMember</th>\n      <th>DisclosedToFriend</th>\n      <th>InjuryLocationType</th>\n      <th>WeaponType1</th>\n      <th>text_length</th>\n      <th>fold</th>\n      <th>prompts</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n      <th>batch_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bjnj</td>\n      <td>Victim is a XX XX. Victim was diagnosed with b...</td>\n      <td>Victim1, a XX XX XX was found hanging in a loa...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>6</td>\n      <td>386</td>\n      <td>1.0</td>\n      <td>&lt;|system|&gt;\\nYou are an expert legal assistant....</td>\n      <td>[128000, 27, 91, 9125, 91, 397, 2675, 527, 459...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 32 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_batch = create_tokenized_batch_fast(df)\n\ntokenized_batch","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:23.390276Z","iopub.execute_input":"2024-09-24T11:14:23.390595Z","iopub.status.idle":"2024-09-24T11:14:23.445215Z","shell.execute_reply.started":"2024-09-24T11:14:23.390563Z","shell.execute_reply":"2024-09-24T11:14:23.444371Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[128000,     27,     91,  ..., 128009, 128009, 128009],\n         [128000,     27,     91,  ..., 128009, 128009, 128009],\n         [128000,     27,     91,  ...,  78191,     91,     29],\n         [128000,     27,     91,  ...,     91,     29, 128009],\n         [128000,     27,     91,  ..., 128009, 128009, 128009]],\n        dtype=torch.int32),\n 'attention_mask': tensor([[1, 1, 1,  ..., 9, 9, 9],\n         [1, 1, 1,  ..., 9, 9, 9],\n         [1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 9],\n         [1, 1, 1,  ..., 9, 9, 9]], dtype=torch.int8)}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Run Inference","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\n# Initialize the model and tokenizer\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_PATH,\n    device_map=DEVICE,\n    torch_dtype=torch.bfloat16,\n    #trust_remote_code=True\n    local_files_only=True,\n)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:14:23.446476Z","iopub.execute_input":"2024-09-24T11:14:23.447173Z","iopub.status.idle":"2024-09-24T11:15:34.841035Z","shell.execute_reply.started":"2024-09-24T11:14:23.447129Z","shell.execute_reply":"2024-09-24T11:15:34.840187Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1610738723f247e98675e52cb6c1ca11"}},"metadata":{}}]},{"cell_type":"code","source":"# Start timing\nstart_time = time.time()\n\n\n#--------------------------\n# Select the fold\n#--------------------------\n\n\n# Select the fold\ndf_data = df_data[df_data['fold'] == TEST_FOLD]\ndf_data = df_data.reset_index(drop=True)\n\nif RUN_TEST == True:\n    #################\n    # For testing only\n\n    num_samples = NUM_SAMPLES\n\n    df_data = df_data[0:num_samples]\n    df_data = df_data.reset_index(drop=True)\n\n    ################\n    \n    \n#--------------------------\n# Create batches\n#--------------------------\n    \n# Save the original order\norig_order = list(df_data['uid'])\n\n# Reorder by text length\ndf_sorted = df_data.sort_values(by='text_length', ascending=True)\ndf_sorted = df_sorted.reset_index(drop=True)\n\n# Assign a batch number to every row\nbatch_size = BATCH_SIZE\ndf_sorted = assign_batch_numbers(df_sorted, batch_size)\n    \n# Get the number of batches by getting\n# the number of unique batch numbers.\nbatch_num_list = list(df_sorted['batch_number'].unique())\nnum_batches = len(batch_num_list)\n\n\n#--------------------------\n# Tokenize each batch\n#--------------------------\n\n\ntokenized_batch_list = []\n\n# Tokenizing is done on the CPU.\n# Tokening batches outside the main inference loop\n# sppeds up inference because the GPU does not need to\n# wait tokenized batches from the CPU.\n\n# Each batch has a different padded length.\n# Doing this one batch at time means batches\n# wth shorter lengths will be processed faster.\nprint('Tokenizing all the batches...')\nfor i in tqdm(range(0, num_batches)):\n    \n    # Get the batch\n    df = df_sorted[df_sorted['batch_number'] == i]\n    df = df.reset_index(drop=True)\n    \n    #tokenized_batch = tokenize_batch(df)\n    tokenized_batch = create_tokenized_batch_fast(df)\n\n    tokenized_batch_list.append(tokenized_batch)\n    \n\n#--------------------------\n# Run inference\n#--------------------------\n\n\nprint('Running inference on each batch...')\nfor i in tqdm(range(0, num_batches)):\n    \n    inputs = tokenized_batch_list[i]\n    \n    # Convert the dictionary to a BatchEncoding object\n    inputs = BatchEncoding(inputs)\n    \n    inputs = inputs.to(DEVICE)\n        \n        \n    df_response = run_slm_with_batches(inputs)\n    \n    if i == 0:\n        df_fin = df_response\n    else:\n        df_fin = pd.concat([df_fin, df_response])\n        \n    torch.cuda.empty_cache()\n    gc.collect()\n    gc.collect()\n    \n        \n\n# Get the inference time\nelapsed_time = timer(start_time)\nelapsed_time = elapsed_time/60\nprint(f\"Time taken: {elapsed_time} minutes\")","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:32.427725Z","iopub.execute_input":"2024-09-24T11:30:32.428487Z","iopub.status.idle":"2024-09-24T11:34:35.845005Z","shell.execute_reply.started":"2024-09-24T11:30:32.428446Z","shell.execute_reply":"2024-09-24T11:34:35.843399Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Tokenizing all the batches...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:00<00:00, 226.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running inference on each batch...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/50 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n  2%|▏         | 1/50 [02:21<1:55:51, 141.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n  4%|▍         | 2/50 [03:25<1:16:47, 95.99s/it] Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n  4%|▍         | 2/50 [04:02<1:37:00, 121.25s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[44], line 91\u001b[0m\n\u001b[1;32m     86\u001b[0m inputs \u001b[38;5;241m=\u001b[39m BatchEncoding(inputs)\n\u001b[1;32m     88\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 91\u001b[0m df_response \u001b[38;5;241m=\u001b[39m \u001b[43mrun_slm_with_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     94\u001b[0m     df_fin \u001b[38;5;241m=\u001b[39m df_response\n","Cell \u001b[0;32mIn[31], line 7\u001b[0m, in \u001b[0;36mrun_slm_with_batches\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m      4\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Generate the outputs from prompt\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m generate_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Decode the generated output\u001b[39;00m\n\u001b[1;32m     14\u001b[0m generated_text_list \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(generate_ids, \n\u001b[1;32m     15\u001b[0m                                     skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m                                     clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2017\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2018\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2019\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2021\u001b[0m     )\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2982\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2985\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1189\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1186\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1001\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    989\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    990\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    991\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    998\u001b[0m         position_embeddings,\n\u001b[1;32m    999\u001b[0m     )\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1001\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:734\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    733\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:617\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    605\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    606\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m    613\u001b[0m     )\n\u001b[1;32m    615\u001b[0m bsz, q_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m--> 617\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\n\u001b[1;32m    619\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:1009\u001b[0m, in \u001b[0;36mLinear8bitLt.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m x\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[1;32m   1007\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m-> 1009\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mhas_fp16_weights:\n\u001b[1;32m   1012\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mCB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mCxB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m         \u001b[38;5;66;03m# we converted 8-bit row major to turing/ampere format in the first inference pass\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m         \u001b[38;5;66;03m# we no longer need the row-major weight\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:556\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(A, B, out, state, threshold, bias)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    555\u001b[0m     state\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m threshold\n\u001b[0;32m--> 556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMatMul8bitLt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py:574\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:395\u001b[0m, in \u001b[0;36mMatMul8bitLt.forward\u001b[0;34m(ctx, A, B, out, bias, state)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_igemmlt:\n\u001b[1;32m    394\u001b[0m     C32A, SA \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mtransform(CA, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 395\u001b[0m     out32, Sout32 \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43migemmlt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC32A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCxB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m bias\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;66;03m# we apply the fused bias here\u001b[39;00m\n\u001b[1;32m    398\u001b[0m         output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmm_dequant(out32, Sout32, SCA, state\u001b[38;5;241m.\u001b[39mSCB, bias\u001b[38;5;241m=\u001b[39mbias)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/functional.py:2372\u001b[0m, in \u001b[0;36migemmlt\u001b[0;34m(A, B, SA, SB, out, Sout, dtype)\u001b[0m\n\u001b[1;32m   2370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m formatB \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol_turing\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mint32:\n\u001b[0;32m-> 2372\u001b[0m         has_error \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcigemmlt_turing_32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptrA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptrB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptrC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptrRowScale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mldb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mldc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2373\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2374\u001b[0m         has_error \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mcigemmlt_turing_8(ptr, m, n, k, ptrA, ptrB, ptrC, ptrRowScale, lda, ldb, ldc)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_fin.shape)\n\n#df_fin.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.592447Z","iopub.status.idle":"2024-09-24T11:30:09.592968Z","shell.execute_reply.started":"2024-09-24T11:30:09.592694Z","shell.execute_reply":"2024-09-24T11:30:09.592719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"Hello. How are you\"\ninputs = tokenizer(prompt, return_tensors=\"pt\")\n\ntype(inputs)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.594624Z","iopub.status.idle":"2024-09-24T11:30:09.595119Z","shell.execute_reply.started":"2024-09-24T11:30:09.594850Z","shell.execute_reply":"2024-09-24T11:30:09.594874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Post process the raw responses","metadata":{}},{"cell_type":"code","source":"# Create a labels dataframe\n\ncols_to_drop = [\"NarrativeLE\", \n                \"NarrativeCME\", \n                \"text_length\", \n                \"fold\", \"prompts\"]\n\ndf_labels = df_data.drop(cols_to_drop, axis=1)\n\ndf_labels = df_labels.set_index('uid')\n\ndf_labels.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.596697Z","iopub.status.idle":"2024-09-24T11:30:09.597188Z","shell.execute_reply.started":"2024-09-24T11:30:09.596931Z","shell.execute_reply":"2024-09-24T11:30:09.596957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Chane the row order back to the original order\n# that existed before sorting by text length.\n\n# Set the \"uid\" column as the index\ndf_fin = df_fin.set_index('uid')\n\n# Go back to the orginal row order\ndf_fin1 = df_fin.reindex(orig_order)\n\n# Reset the index while keeping the \"uid\" column\ndf_fin1 = df_fin1.reset_index(drop=False)\n\n#df_fin1.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.598498Z","iopub.status.idle":"2024-09-24T11:30:09.599022Z","shell.execute_reply.started":"2024-09-24T11:30:09.598720Z","shell.execute_reply":"2024-09-24T11:30:09.598765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_labels.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.600397Z","iopub.status.idle":"2024-09-24T11:30:09.600772Z","shell.execute_reply.started":"2024-09-24T11:30:09.600592Z","shell.execute_reply":"2024-09-24T11:30:09.600610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Post process the response\ndf_preds = post_process_responses(df_fin1)\n\n\n# Save the raw preds for analysis later\npath = \"df_raw_preds.csv\"\ndf_preds.to_csv(path, index=False)\n\n\n# Change the values from yes or no\n# to 0 or 1\n\n# Define the mapping function\ndef yes_no_to_binary(x):\n    if type(x) == str:\n        x = x.lower()\n        if x == 'yes':\n            return 1\n        elif x == 'no':\n            return 0\n        else:\n            return 0 # In case the model outputs \"unknown\" or \"none\"\n    else:\n        return x\n\n    \ndf_preds = df_preds.set_index('uid')\n\n# Apply the function to the entire dataframe\ndf_preds = df_preds.applymap(yes_no_to_binary)\n\n# Make sure all values are int and not NaN\ndf_preds = df_preds.round().astype(int)\n\n# Check that there are 23 target variables\nassert df_preds.shape[1] == 23\n\n# Check that column order and row order are the same\nassert (df_preds.index == df_labels.index).all()\n\n# All values should be integers\nassert (df_preds.dtypes == int).all()\n\ndf_preds.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.602379Z","iopub.status.idle":"2024-09-24T11:30:09.602752Z","shell.execute_reply.started":"2024-09-24T11:30:09.602569Z","shell.execute_reply":"2024-09-24T11:30:09.602588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate the predictions","metadata":{}},{"cell_type":"code","source":"# [1] Get the baseline accuracy aand f1 score if\n# the model predicted all zeros for\n# the binary features and predicted the majority class for\n# 'InjuryLocationType' (1) and 'WeaponType1' (5)\n\n# Convert to numpy\nnp_labels = df_labels.to_numpy()\nnp_preds = df_preds.to_numpy()\n\n\n# Create a matrix with all values 0\nnp_preds_baseline = np_preds * 0\n\n\"\"\"\n# Biased probabilities\n\nnum_rows = df_labels.shape[0]\nnum_cols = df_labels.shape[1]\n\n# Define the probabilities for 0 and 1\nprobabilities = [0.2, 0.8]  # 80% chance of 0, 20% chance of 1\n\n# Create the array with biased probabilities\nnp_preds_baseline = np.random.choice([0, 1], \n                                     size=(num_rows, num_cols), \n                                     p=probabilities)\n\"\"\"\n\n# Set the second last column to 1 (InjuryLocationType)\nnp_preds_baseline[:, -2] = 1\n# Set the last column to 5 (WeaponType1)\nnp_preds_baseline[:, -1] = 5\n\n# Get the total number of entries in the dataframe\ntotal = np_labels.size\n\n# Element-wise comparison\nmatches = np_labels == np_preds_baseline\n\n# Count number of matches\nnum_matches = np.sum(matches)\n\n# Accuracy\nacc = num_matches/total\n\n# Calculate f1 score\nexcluded_list = ['InjuryLocationType', 'WeaponType1']\n\n# Get a list of columns\ncol_list = list(df_preds.columns)\n\n# Make a copy of df_preds\ndf_preds_zeros = df_preds.copy()\n\n# Set column values to 0\n# Remember the 'uid' column is the index\nfor item in col_list:\n    if item not in excluded_list:\n        # Set all values to 0\n        #df_preds_zeros[item] = 0\n        \n        # The biased_coin function returns either 0 or 1.\n        # p_zero is the probability that the function will return 0.\n        df_preds_zeros[item] = biased_coin(p_zero=0.0)\n\n# Set values to the majority class\ndf_preds_zeros['InjuryLocationType'] = 1\ndf_preds_zeros['WeaponType1'] = 5\n\nf1_score_avg = calculate_f1(df_preds_zeros, df_labels)\n\nprint(f\"F1 score (pred ones): {f1_score_avg}\")\nprint(f\"Accuracy (pred zeros): {acc}\")\nprint(f\"Total: {total}\")\nprint(f\"Num matches: {num_matches}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.604158Z","iopub.status.idle":"2024-09-24T11:30:09.604513Z","shell.execute_reply.started":"2024-09-24T11:30:09.604335Z","shell.execute_reply":"2024-09-24T11:30:09.604353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# [2] Get the model pred accuracy and f1 score\n\n# Convert to numpy\nnp_labels = df_labels.to_numpy()\nnp_preds_model = df_preds.to_numpy()\n\n# Get the total number of entries in the dataframe\ntotal = np_labels.size\n\n# Element-wise comparison\nmatches = np_labels == np_preds_model\n\n# Count number of matches\nnum_matches = np.sum(matches)\n\n\n# Accuracy\nacc = num_matches/total\n\nf1_score_avg = calculate_f1(df_preds, df_labels)\n\nprint(f\"F1 score: {f1_score_avg}\")\nprint(f\"Accuracy: {acc}\")\nprint(f\"Total: {total}\")\nprint(f\"Num matches: {num_matches}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.605737Z","iopub.status.idle":"2024-09-24T11:30:09.606179Z","shell.execute_reply.started":"2024-09-24T11:30:09.605969Z","shell.execute_reply":"2024-09-24T11:30:09.605997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save the preds","metadata":{}},{"cell_type":"code","source":"# Save the dataframes for analysis later\n\npath = \"df_preds.csv\"\ndf_preds.to_csv(path, index=False)\n\n!ls","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.607469Z","iopub.status.idle":"2024-09-24T11:30:09.607827Z","shell.execute_reply.started":"2024-09-24T11:30:09.607645Z","shell.execute_reply":"2024-09-24T11:30:09.607663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check if df_preds meets the submission requirements","metadata":{}},{"cell_type":"code","source":"path = base_path + 'submission_format_OfwLSFE.csv'\ndf_sample = pd.read_csv(path)\n\ndf_sample = df_sample[0:NUM_SAMPLES]\n\ndf_sample = df_sample.set_index('uid')\n\nprint(df_sample.shape)\n\ndf_sample.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.608726Z","iopub.status.idle":"2024-09-24T11:30:09.609112Z","shell.execute_reply.started":"2024-09-24T11:30:09.608902Z","shell.execute_reply":"2024-09-24T11:30:09.608944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_preds.index = df_sample.index\n\ndf_preds.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.610548Z","iopub.status.idle":"2024-09-24T11:30:09.610926Z","shell.execute_reply.started":"2024-09-24T11:30:09.610723Z","shell.execute_reply":"2024-09-24T11:30:09.610747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Ensure the range of the predicted values is correct\n\n# predictions[\"InjuryLocationType\"] = 1 (1 to 6)\n# predictions[\"WeaponType1\"] = 5 (1 to 12)\n\ndef check_col_InjuryLocationType(x):\n    \n    if x < 1:\n        return 1\n    elif x > 6:\n        return 1\n    else:\n        return x\n    \ndf_preds['InjuryLocationType'] = df_preds['InjuryLocationType'].apply(check_col_InjuryLocationType)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.611889Z","iopub.status.idle":"2024-09-24T11:30:09.612272Z","shell.execute_reply.started":"2024-09-24T11:30:09.612095Z","shell.execute_reply":"2024-09-24T11:30:09.612113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions[\"InjuryLocationType\"] = 1 (1 to 6)\n# predictions[\"WeaponType1\"] = 5 (1 to 12)\n\ndef check_col_WeaponType1(x):\n    \n    if x < 1:\n        return 5\n    elif x > 12:\n        return 5\n    else:\n        return x\n    \ndf_preds['WeaponType1'] = df_preds['WeaponType1'].apply(check_col_WeaponType1)\n ","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.613273Z","iopub.status.idle":"2024-09-24T11:30:09.613632Z","shell.execute_reply.started":"2024-09-24T11:30:09.613447Z","shell.execute_reply":"2024-09-24T11:30:09.613466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check that the binary features only\n# have values that are either 1 or 0\n\ndef check_binary_col(x):\n    \n    answer_list = [0, 1]\n    \n    if x not in answer_list:\n        return 0\n    else:\n        return x\n    \n    \ncol_list = ['DepressedMood',\n       'MentalIllnessTreatmentCurrnt', 'HistoryMentalIllnessTreatmnt',\n       'SuicideAttemptHistory', 'SuicideThoughtHistory',\n       'SubstanceAbuseProblem', 'MentalHealthProblem', 'DiagnosisAnxiety',\n       'DiagnosisDepressionDysthymia', 'DiagnosisBipolar', 'DiagnosisAdhd',\n       'IntimatePartnerProblem', 'FamilyRelationship', 'Argument',\n       'SchoolProblem', 'RecentCriminalLegalProblem', 'SuicideNote',\n       'SuicideIntentDisclosed', 'DisclosedToIntimatePartner',\n       'DisclosedToOtherFamilyMember', 'DisclosedToFriend']\n\n# Check every binary column\nfor col in col_list:\n    \n    df_preds[col] = df_preds[col].apply(check_binary_col)\n    \ndf_preds.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.615139Z","iopub.status.idle":"2024-09-24T11:30:09.615625Z","shell.execute_reply.started":"2024-09-24T11:30:09.615358Z","shell.execute_reply":"2024-09-24T11:30:09.615383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check that there are 23 target variables\nassert df_preds.shape[1] == 23\n\n# Check that column order and row order are the same\nassert (df_preds.index == df_sample.index).all()\n\n# All values should be integers\nassert (df_preds.dtypes == int).all()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.617001Z","iopub.status.idle":"2024-09-24T11:30:09.617375Z","shell.execute_reply.started":"2024-09-24T11:30:09.617188Z","shell.execute_reply":"2024-09-24T11:30:09.617207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Columns are in the correct order\nassert (df_sample.columns == df_preds.columns).all().all()\n\n# All columns are of type int\nassert (df_preds.dtypes == int).all()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.618870Z","iopub.status.idle":"2024-09-24T11:30:09.619256Z","shell.execute_reply.started":"2024-09-24T11:30:09.619076Z","shell.execute_reply":"2024-09-24T11:30:09.619095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Variables have values within the expected range\nassert df_preds.iloc[:, 0:-2].isin([0, 1]).all().all()\nassert (df_preds[\"InjuryLocationType\"].isin(range(1, 7))).all()\nassert (df_preds[\"WeaponType1\"].isin(range(1, 13))).all()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.620801Z","iopub.status.idle":"2024-09-24T11:30:09.621170Z","shell.execute_reply.started":"2024-09-24T11:30:09.620990Z","shell.execute_reply":"2024-09-24T11:30:09.621009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a requirements.txt file\n\n!pip freeze > requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:30:09.622572Z","iopub.status.idle":"2024-09-24T11:30:09.622957Z","shell.execute_reply.started":"2024-09-24T11:30:09.622753Z","shell.execute_reply":"2024-09-24T11:30:09.622772Z"},"trusted":true},"execution_count":null,"outputs":[]}]}